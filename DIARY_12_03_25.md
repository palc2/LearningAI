# Daily Vocabulary Feature - Feature Development & Bug Fixes

## Date: December 3, 2025

## Overview
Today we built a complete **Daily Vocabulary** feature that analyzes conversation logs stored in the database and displays the most frequently used words and phrases. The feature extracts top 3 nouns, top 3 verbs, and top 1 phrase from daily conversation turns, provides Chinese translations, and includes English audio playback. We also fixed critical bugs related to token limits and timezone handling.

## Feature: Daily Vocabulary Analysis

### Feature Description
A new product feature that leverages the daily conversation log stored in the database. The feature:
- Analyzes `translated_text` from `conversation_turns` table
- Extracts the most frequently used vocabulary by date
- Returns English words/phrases with Chinese translations
- Provides English audio playback for pronunciation practice
- Displays results in a clean, organized UI

### User Experience Flow
1. User navigates to `/vocabulary` page from home
2. Date picker defaults to a specific date (e.g., 2025-12-02)
3. User can select any date to view vocabulary for that day
4. System queries conversation turns for the selected date (filtered by household timezone)
5. AI analyzes the English translations and extracts:
   - Top 3 most frequently used nouns
   - Top 3 most frequently used verbs  
   - Top 1 most frequently used phrase (2-5 words)
6. Each word/phrase is translated to Chinese
7. Results displayed with:
   - English word/phrase
   - Chinese translation
   - Usage frequency count
   - Audio playback button (English TTS)

### Design Decisions

#### Data Source
- **Table**: `conversation_turns`
- **Field**: `translated_text` (English translations from mom's turns: zh → en)
- **Filter**: Only `target_lang = 'en-US'` (mom's turns)
- **Date Filter**: Uses household timezone via `DATE(ended_at AT TIME ZONE timezone) = date`

#### Analysis Approach
- **Method**: AI-powered analysis using GPT-5
- **Input**: Combined English text from all conversation turns for the date
- **Output**: Structured JSON with nouns, verbs, and phrase with frequency counts
- **Translation**: Each word/phrase translated individually to Chinese using translation API

#### UI Design
- **Layout**: Clean, card-based design with color coding:
  - Blue cards for nouns
  - Green cards for verbs
  - Purple card for phrase
- **Information Display**: 
  - Rank number (1, 2, 3)
  - English word/phrase (large, bold)
  - Chinese translation (medium, gray)
  - Usage count (small, gray)
  - Play button for audio
- **Empty States**: Clear messaging when no data found
- **Loading States**: Spinner with descriptive text

#### Timezone Handling
- **Database**: Stores timestamps as `TIMESTAMPTZ` (timezone-aware)
- **Query**: Filters by date in household's timezone (default: `America/New_York`)
- **UI**: Displays dates using the same timezone from API response
- **Consistency**: Ensures dates match between database queries and UI display

## Key Achievements

### 1. Feature Implementation
- ✅ Built complete API endpoint `/api/vocabulary/daily`
- ✅ Created frontend page `/vocabulary` with date picker
- ✅ Implemented AI-powered vocabulary extraction
- ✅ Added Chinese translation for all words/phrases
- ✅ Integrated English audio playback (Web Speech API)
- ✅ Added navigation link from home page
- ✅ Implemented proper timezone handling

### 2. Fixed Token Limit Issues
- ✅ Increased `max_tokens` from 800/900 → 2000 across all API calls
- ✅ Prevented response truncation that was causing incomplete JSON
- ✅ Fixed AI fallback extraction to also use 2000 tokens

### 2. Improved Prompt Engineering
- ✅ Dramatically simplified prompt from ~500 chars to ~150 chars
- ✅ Removed verbose instructions that caused model to generate explanations
- ✅ Created ultra-concise prompt: "Extract top 3 nouns, top 3 verbs, and top 1 phrase from this text. Return ONLY JSON, no other text."
- ✅ Included compact JSON format example in single line
- ✅ Reduced `max_tokens` from 2000 → 1000 (sufficient with concise prompt)

### 3. Fixed Timezone Consistency
- ✅ Updated API to use household timezone for date filtering
- ✅ Query now uses `DATE(ended_at AT TIME ZONE timezone) = date` pattern
- ✅ API returns timezone in response for UI consistency
- ✅ Frontend displays dates using timezone from API
- ✅ Date picker uses local dates (YYYY-MM-DD) interpreted in household timezone

### 4. Enhanced JSON Extraction
- ✅ Improved JSON extraction to handle incomplete responses
- ✅ Added auto-closing of incomplete brackets/braces
- ✅ Better handling of trailing commas and malformed JSON
- ✅ Enhanced error recovery with improved AI fallback extraction

### 5. Added Comprehensive Logging
- ✅ Added logging after JSON parsing to see extracted data
- ✅ Logging before/after A1 word filtering
- ✅ Logging of items to translate with actual words/phrases
- ✅ Logging of translation results and final output counts
- ✅ Better debugging information at each step

### 6. Fixed Data Filtering
- ✅ Removed padding with empty items (was causing confusion)
- ✅ Proper filtering to only return items with valid words/phrases AND translations
- ✅ Fixed final result construction to use translated arrays directly
- ✅ Ensured empty items are filtered out at every stage

## Technical Architecture

### API Endpoint: `/api/vocabulary/daily`
**Method**: GET  
**Parameters**:
- `date` (optional): YYYY-MM-DD format, defaults to today
- `householdId` (optional): UUID, defaults to default household

**Process Flow**:
1. Parse and validate date parameter
2. Fetch household timezone from database
3. Query conversation turns for date in household timezone
4. Filter to English translations only (`target_lang = 'en-US'`)
5. Combine all translated texts
6. Send to AI for vocabulary analysis
7. Parse JSON response (nouns, verbs, phrase with counts)
8. Translate each word/phrase to Chinese (parallel)
9. Return structured response with translations

**Response Format**:
```json
{
  "date": "2025-12-02",
  "turnCount": 26,
  "nouns": [
    {"word": "baby", "translation": "宝宝", "count": 5},
    {"word": "milk", "translation": "牛奶", "count": 4},
    {"word": "diaper", "translation": "尿布", "count": 3}
  ],
  "verbs": [
    {"word": "need", "translation": "需要", "count": 6},
    {"word": "help", "translation": "帮助", "count": 5},
    {"word": "change", "translation": "换", "count": 4}
  ],
  "phrase": {
    "phrase": "can you help",
    "translation": "你能帮忙吗",
    "count": 3
  },
  "timezone": "America/New_York"
}
```

### Frontend Page: `/vocabulary`
**Components**:
- Date picker (HTML5 date input)
- Vocabulary display cards (nouns, verbs, phrase)
- Audio playback buttons (Web Speech API)
- Loading and error states
- Empty state messaging

**State Management**:
- `date`: Selected date (YYYY-MM-DD)
- `data`: Vocabulary data from API
- `loading`: Loading state
- `error`: Error message
- `playingItem`: Currently playing audio item ID

**Audio Playback**:
- Uses `speakText()` from `lib/tts.ts`
- Web Speech API with `en-US` language
- Visual feedback during playback
- Prevents multiple simultaneous plays

## Problem Analysis

### Root Cause
The vocabulary analysis feature had several issues:

1. **Token Limit Too Low**: `max_tokens: 2000` was hit because model generated verbose responses
2. **Verbose Prompt**: Long prompt (~500 chars) caused model to generate explanations
3. **Response Truncation**: AI responses cut off (`finishReason: 'length'`) before JSON completion
4. **Timezone Mismatch**: API used UTC dates while database stored timezone-aware timestamps
5. **Failed Extraction**: Incomplete JSON couldn't be parsed, resulting in empty arrays

### Symptoms Observed
- Console logs showed: "verbs and nouns and phrases being counted by its frequency"
- UI displayed blank sections under each category
- API returned: `{ nouns: 0, verbs: 0, phrases: 0 }`
- Logs showed: "Successfully extracted JSON using AI fallback" but still empty results

## Technical Details

### Token Limit Strategy
- **Initial**: 500 tokens (too low)
- **Increased to**: 2000 tokens (still hit limit due to verbose responses)
- **Final Solution**: 1000 tokens with ultra-concise prompt
- **Rationale**: Concise prompt prevents verbose output, 1000 tokens sufficient for small JSON response

### Prompt Evolution
- **Version 1**: ~500 characters with detailed instructions → Generated verbose explanations
- **Version 2**: ~200 characters with example JSON → Still verbose
- **Final Version**: ~150 characters, ultra-concise:
  ```
  Extract top 3 nouns, top 3 verbs, and top 1 phrase from this text. Return ONLY JSON, no other text.
  
  Text: {text}
  
  JSON format:
  {"nouns":[{"word":"word","count":5}],"verbs":[{"word":"word","count":6}],"phrase":{"phrase":"phrase","count":3}}
  ```
- **Result**: Model returns concise JSON only, fits within 1000 tokens

### JSON Extraction Enhancements
1. **Auto-completion**: Closes incomplete brackets/braces if response is truncated
2. **Trailing Comma Handling**: Removes trailing commas before parsing
3. **Better Fallback**: Improved AI extraction with higher token limits
4. **Validation**: Ensures parsed JSON has expected structure before proceeding

### Logging Strategy
Added strategic logging points:
- After JSON parsing: Shows what was extracted (counts, sample words)
- Before A1 filtering: Shows raw counts
- After A1 filtering: Shows filtered counts and which words were excluded
- Items to translate: Shows actual words/phrases being sent for translation
- Translation results: Shows success counts and totals
- Final results: Shows final counts returned to UI

## Files Created/Modified

### New Files Created
1. **`app/api/vocabulary/daily/route.ts`** (NEW)
   - Complete API endpoint for vocabulary analysis
   - Handles date parsing, timezone conversion, AI analysis, translations
   - Returns structured vocabulary data

2. **`app/vocabulary/page.tsx`** (NEW)
   - Complete frontend page for vocabulary display
   - Date picker, vocabulary cards, audio playback
   - Loading, error, and empty states

### Modified Files
1. **`app/page.tsx`**
   - Added "Daily Vocabulary →" navigation link

2. **`app/api/vocabulary/daily/route.ts`** (iterative improvements)
   - Simplified prompt dramatically (500 → 150 chars)
   - Adjusted `max_tokens` (500 → 2000 → 1000)
   - Added household timezone support
   - Improved error handling for token limit issues
   - Added comprehensive logging
   - Fixed JSON extraction for partial responses

## Performance & User Experience

### Input Processing
- **Text Length**: ~692 characters for 15 conversation turns
- **Token Estimate**: ~150-200 tokens (1 token ≈ 3-4 characters)
- **Processing Time**: ~2-3 seconds for AI analysis + translations

### Response Size
- **Expected JSON**: ~200-300 characters
- **Token Count**: ~50-100 tokens
- **With Buffer**: 1000 tokens provides 10x headroom

### User Experience Flow
1. User selects date → Instant feedback (loading spinner)
2. API processes → 2-3 seconds for analysis
3. Results display → Organized cards with translations
4. Audio playback → Instant TTS using browser API
5. Date changes → Automatic refresh with new data

### Before vs After
**Before**:
- API responses cut off due to token limits
- JSON extraction failed on incomplete responses
- UI displayed blank sections
- Dates mismatched between database and UI
- Debugging difficult (limited logging)

**After**:
- API responses complete and concise ✅
- JSON extraction handles edge cases gracefully ✅
- UI displays vocabulary items correctly ✅
- Dates consistent with database timezone ✅
- Comprehensive logging for debugging ✅

## Known Issues Resolved

1. ✅ Responses cut off due to low `max_tokens` → Fixed with 2000 tokens
2. ✅ Model generating verbose explanations → Fixed with improved prompt
3. ✅ JSON extraction failing on incomplete responses → Fixed with auto-completion
4. ✅ Empty arrays being returned → Fixed with proper filtering and validation
5. ✅ Difficult to debug issues → Fixed with comprehensive logging

## Design Principles Applied

### 1. Data-Driven Learning
- Leverages actual conversation data stored in database
- Provides personalized vocabulary based on real usage
- Helps users learn words they actually use in conversations

### 2. Bilingual Support
- English words with Chinese translations
- Supports both languages in the family context
- Audio playback for pronunciation practice

### 3. Timezone Awareness
- Respects household timezone for accurate date filtering
- Consistent date display across database and UI
- Prevents confusion from timezone mismatches

### 4. Progressive Enhancement
- Works with basic date selection
- Enhanced with audio playback (graceful degradation)
- Clear empty states when no data available

### 5. Performance Optimization
- Concise prompts reduce API costs and latency
- Parallel translation requests for faster processing
- Efficient database queries with proper indexing

## Testing Notes

- ✅ Tested with 26 conversation turns for date 2025-12-02
- ✅ Tested with dates having no data (proper empty state)
- ✅ Verified timezone consistency (dates match database)
- ✅ Tested audio playback for all word types
- ✅ Verified error handling for token limit issues
- ✅ Console logs show detailed extraction and filtering process
- ✅ UI displays vocabulary items correctly with translations

## Known Limitations & Future Improvements

### Current Limitations
1. Only analyzes English translations (mom's turns)
2. Fixed to top 3 nouns, 3 verbs, 1 phrase (could be configurable)
3. No caching (re-analyzes on each request)
4. Requires AI API calls for each analysis

### Future Enhancements
1. **Caching**: Cache vocabulary results per date/household
2. **Configurability**: Allow users to select number of items (top 5, top 10, etc.)
3. **Historical Trends**: Show vocabulary trends over time
4. **Word Details**: Add definitions, example sentences, part of speech
5. **Export**: Allow exporting vocabulary lists for study
6. **Spaced Repetition**: Integrate with learning system
7. **Phrase Variations**: Show related phrases or synonyms
8. **Structured Output**: Use API structured output if available
9. **Batch Processing**: Analyze multiple dates at once
10. **Progress Tracking**: Track which words user has learned

---

**Status**: ✅ Feature complete and working
**UI Display**: ✅ Shows vocabulary items correctly with translations
**Timezone**: ✅ Consistent with database timezone
**Audio Playback**: ✅ Working with Web Speech API
**Error Handling**: ✅ Handles token limits and edge cases gracefully
**Debugging**: ✅ Comprehensive logging added for troubleshooting

